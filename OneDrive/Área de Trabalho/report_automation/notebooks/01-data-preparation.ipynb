{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25eaaf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original Olist datasets...\n",
      "Datasets loaded successfully.\n",
      "Merging orders and payments tables...\n",
      "Filtered data for 2018-08-01. Found 331 records.\n",
      "\n",
      "SUCCESS! File 'daily_sales_2018-08-01.csv' has been created in the '../data' folder.\n",
      "Full path: c:\\Users\\gisro\\OneDrive\\√Årea de Trabalho\\report_automation\\data\\daily_sales_2018-08-01.csv\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Data Preparation for the Daily Sales Report Automator\n",
    "# -------------------------------------------------------------------\n",
    "# This notebook simulates a daily data file from the main Olist dataset.\n",
    "# The output is a single CSV file that the main Python script will process.\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 1. Load Original Datasets ---\n",
    "print(\"Loading original Olist datasets...\")\n",
    "try:\n",
    "    # Assumes the Olist CSVs are in the same 'notebooks' folder for this preparation step\n",
    "    orders = pd.read_csv('olist_orders_dataset.csv')\n",
    "    payments = pd.read_csv('olist_order_payments_dataset.csv')\n",
    "    print(\"Datasets loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: Olist source files not found in the 'notebooks/' directory.\")\n",
    "    raise\n",
    "\n",
    "# --- 2. Process and Merge Data ---\n",
    "print(\"Merging orders and payments tables...\")\n",
    "df_merged = pd.merge(orders, payments, on='order_id')\n",
    "\n",
    "# Convert timestamp to datetime objects\n",
    "df_merged['order_purchase_timestamp'] = pd.to_datetime(df_merged['order_purchase_timestamp'])\n",
    "\n",
    "# --- 3. Filter for a Specific Day to Simulate a Daily Report ---\n",
    "target_date = '2018-08-01'\n",
    "daily_data = df_merged[df_merged['order_purchase_timestamp'].dt.date == pd.to_datetime(target_date).date()].copy()\n",
    "print(f\"Filtered data for {target_date}. Found {len(daily_data)} records.\")\n",
    "\n",
    "# --- 4. Define Output Path and Save the File ---\n",
    "# The path goes up one level ('..') from 'notebooks/' to the project root, then into 'data/'\n",
    "output_folder = '../data'\n",
    "output_filename = f'daily_sales_{target_date}.csv'\n",
    "output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "# Ensure the target directory exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Save the filtered dataframe to the data folder\n",
    "daily_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\nSUCCESS! File '{output_filename}' has been created in the '{output_folder}' folder.\")\n",
    "print(f\"Full path: {os.path.abspath(output_path)}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
